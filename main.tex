\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%Template version as of 6/27/2024

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}


\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Proposal: A Comprehensive Survey on Learning Hash for Image Retrieval}

\author{\IEEEauthorblockN{1\textsuperscript{st} Ba Cong Nguyen}
\IEEEauthorblockA{\textit{Faculty of Information Technology} \\
\textit{University of Science, VNU-HCM}\\
Ho Chi Minh City, Vietnam \\
nbcong22@clc.fitus.edu.vn}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Tran Anh Khoa Dang}
\IEEEauthorblockA{\textit{Faculty of Information Technology} \\
\textit{University of Science, VNU-HCM}\\
Ho Chi Minh City, Vietnam \\
dtakhoa22@clc.fitus.edu.vn}
% \and
% \IEEEauthorblockN{3\textsuperscript{rd} Given Name Surname}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% City, Country \\
% email address or ORCID}
% \and
% \IEEEauthorblockN{4\textsuperscript{th} Given Name Surname}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% City, Country \\
% email address or ORCID}
% \and
% \IEEEauthorblockN{5\textsuperscript{th} Given Name Surname}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% City, Country \\
% email address or ORCID}
% \and
% \IEEEauthorblockN{6\textsuperscript{th} Given Name Surname}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% City, Country \\
% email address or ORCID}
}

\maketitle

\begin{abstract}
The rapid growth of image datasets has made traditional image retrieval methods inefficient, 
both in terms of accuracy and scalability. Hashing-based techniques provide a promising solution by 
encoding high-dimensional image data into compact binary codes, enabling fast retrieval with minimal 
storage requirements. 
In this paper, we introduce Deep Supervised Hashing, an advanced approach for retrieving images from large-scale datasets. 
This method leverages deep learning to generate highly discriminative hash codes, 
improving retrieval accuracy while maintaining computational efficiency.
 Although Deep Supervised Hashing has demonstrated its effectiveness in large-scale image search tasks, 
 there remains substantial room for further enhancement. Various factors, such as the optimization of hash 
 function learning, the handling of semantic relationships in image data, and the robustness of hash codes 
 against variations, present opportunities for improvement.
 To address these challenges, we explore several advancements in Deep Supervised Hashing methodologies.
 By analyzing existing techniques and identifying potential refinements, 
 we aim to contribute to the ongoing development of more accurate, efficient, and scalable image retrieval systems.

 \end{abstract}


\begin{IEEEkeywords}
hashing, image retrieval, deep learning
\end{IEEEkeywords}


\input{chapters/intro.tex}

\input{chapters/related-work.tex}

% Tell about the advantages of proposed methods

% What are you going to do here? Tell the way you 
% Train all 3 proposed models (list included) and conduct comparisons 
  
\section{Methodology}

In this project, we aim to compare various deep learning based hashing models (or methods) in a multitude of aspects (such as training, runtime and general efficiency of resources) to hopefully find out the most effective model in general.
The models will all be fed the same dataset and operated on the same device to ensure that the comparison is as impartial as possible, as different machinesâ€™ processing power and datasets certainly will make or break some parts of the algorithms.
If our goal is to be accomplished, then there are certain steps to follow:
\begin{enumerate}
    \item Finding at least one suitable dataset to feed into the models. Some proposed datasets are MNIST digits dataset, MNIST Kuzushiji dataset and Cifar 10 dataset.
    \item Implementing, evaluating and making inferences to assess each individual hashing model using Python (more specifically, Pytorch).
    \item Draw conclusions based on the performance of each model using the datasets, while comparing certain aspects to see if any model exceeds or falls short in one key point or another.
    
\end{enumerate}

\section{Expected Outcomes}

\begin{enumerate}
    \item Clear comparisons and analysis on various techniques.
    \item High-quality binary hash codes that achieve a balance between semantic richness and compactness.
    \item Scalability of the system to handle large datasets efficiently while maintaining high retrieval accuracy.
    \item Comprehensive benchmarking results that position the proposed method as a leader in learning-based hashing for image retrieval.
    
\end{enumerate}
\section*{Acknowledgment}

\section*{References}
\end{document}
