%===============================================================================
% Sample bibliopgraphy file for ifaconf.bst style to be used in
% IFAC meeting papers
% Copyright (c) 2007-2008 International Federation of Automatic Control
%===============================================================================
@InProceedings{Liu_2016_CVPR,
  author = {Liu, Haomiao and Wang, Ruiping and Shan, Shiguang and Chen, Xilin},
  title = {Deep Supervised Hashing for Fast Image Retrieval},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  month = {June},
  year = {2016}
}


@misc{li_2016,
      title={Feature Learning based Deep Supervised Hashing with Pairwise Labels}, 
      author={Wu-Jun Li and Sheng Wang and Wang-Cheng Kang},
      year={2016},
      eprint={1511.03855},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1511.03855}, 
}

@inproceedings{dsdh_2017,
author = {Li, Qi and Sun, Zhenan and He, Ran and Tan, Tieniu},
title = {Deep supervised discrete hashing},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {With the rapid growth of image and video data on the web, hashing has been extensively studied for image or video search in recent years. Benefiting from recent advances in deep learning, deep hashing methods have achieved promising results for image retrieval. However, there are some limitations of previous deep hashing methods (e.g., the semantic information is not fully exploited). In this paper, we develop a deep supervised discrete hashing algorithm based on the assumption that the learned binary codes should be ideal for classification. Both the pairwise label information and the classification information are used to learn the hash codes within one stream framework. We constrain the outputs of the last layer to be binary codes directly, which is rarely investigated in deep hashing algorithm. Because of the discrete nature of hash codes, an alternating minimization method is used to optimize the objective function. Experimental results have shown that our method outperforms current state-of-the-art methods on benchmark datasets.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {2479â€“2488},
numpages = {10},
location = {Long Beach, California, USA},
series = {NIPS'17}
}